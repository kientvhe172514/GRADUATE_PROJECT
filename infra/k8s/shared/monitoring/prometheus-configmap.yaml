apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
  labels:
    app: prometheus
    tier: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 30s      # Optimized for test/dev (was 15s)
      evaluation_interval: 30s  # Optimized for test/dev (was 15s)
      external_labels:
        cluster: 'microservices-cluster'
        environment: 'development'  # Changed from production

    rule_files:
      - "/etc/prometheus/alert_rules.yml"
      - "/etc/prometheus/recording_rules.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager-srv.monitoring.svc:9093  # Fixed: use service name

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

      - job_name: 'microservices'
        kubernetes_sd_configs:
          - role: service
            namespaces:
              names:
                - default
                - graduate-project  # Added: Scrape services in graduate-project namespace
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_service_name

      - job_name: 'infrastructure'
        kubernetes_sd_configs:
          - role: service
            namespaces:
              names:
                - infrastructure
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: job

  alert_rules.yml: |
    groups:
      - name: microservice.rules
        rules:
          - alert: HighErrorRate
            expr: sum(rate(http_requests_total{status=~"4..|5.."}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service) > 0.1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High error rate detected"
              description: "Service {{ $labels.service }} has error rate above 10%"

          - alert: HighResponseTime
            expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) > 2
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High response time detected"
              description: "Service {{ $labels.service }} 95th percentile response time is above 2s"

          - alert: PodCPUUsageHigh
            expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (pod) > 0.8
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod CPU usage high"
              description: "Pod {{ $labels.pod }} CPU usage is above 80%"

          - alert: PodMemoryUsageHigh
            expr: sum(container_memory_usage_bytes) by (pod) / sum(container_spec_memory_limit_bytes) by (pod) > 0.8
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod memory usage high"
              description: "Pod {{ $labels.pod }} memory usage is above 80%"

          - alert: ServiceDown
            expr: up == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Service {{ $labels.instance }} down"
              description: "Service {{ $labels.instance }} is not responding"
          
          # PostgreSQL Alerts
          - alert: PostgreSQLConnectionsHigh
            expr: sum(pg_stat_database_numbackends) > 450
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "PostgreSQL connections near limit"
              description: "{{ $value }} connections active (limit: 500)"
          
          - alert: PostgreSQLConnectionsCritical
            expr: sum(pg_stat_database_numbackends) > 480
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "PostgreSQL connections CRITICAL"
              description: "{{ $value }} connections active (limit: 500) - IMMEDIATE ACTION REQUIRED"
          
          # Redis Alerts
          - alert: RedisCacheLowHitRatio
            expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) * 100 < 80
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Redis cache hit ratio low"
              description: "Hit ratio: {{ $value }}% (should be >80%)"
          
          - alert: RedisConnectionsHigh
            expr: redis_connected_clients > 4500
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Redis connections high"
              description: "{{ $value }} clients connected (limit: 5000)"
          
          # RabbitMQ Alerts
          - alert: RabbitMQQueueGrowth
            expr: rabbitmq_queue_messages_ready > 1000
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "RabbitMQ queue growing"
              description: "Queue {{ $labels.queue }} has {{ $value }} messages"
          
          - alert: RabbitMQConnectionsHigh
            expr: rabbitmq_connections > 1800
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "RabbitMQ connections high"
              description: "{{ $value }} connections (limit: 2000)"
          
          # Kubernetes Alerts
          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Pod crash looping"
              description: "Pod {{ $labels.pod }} in {{ $labels.namespace }} is restarting frequently"
          
          - alert: PodNotReady
            expr: kube_pod_status_phase{phase!="Running"} == 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod not ready"
              description: "Pod {{ $labels.pod }} in {{ $labels.namespace }} is in {{ $labels.phase }} state"
          
          # üõ°Ô∏è DISK PRESSURE ALERTS - Tr√°nh tr√†n ·ªï c·ª©ng
          - alert: NodeDiskPressure
            expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "üö® Node {{ $labels.node }} has DISK PRESSURE"
              description: "Node {{ $labels.node }} is running out of disk space. CHECK LOGS IMMEDIATELY!"
          
          - alert: NodeFilesystemUsageHigh
            expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 20
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Node filesystem usage high"
              description: "Node {{ $labels.instance }} root filesystem has less than 20% free space ({{ $value }}% free)"
          
          - alert: NodeFilesystemUsageCritical
            expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "üö® Node filesystem CRITICAL"
              description: "Node {{ $labels.instance }} root filesystem has less than 10% free space ({{ $value }}% free) - CHECK FLUENTD LOGS!"
          
          # üõ°Ô∏è FLUENTD SPECIFIC ALERTS
          - alert: FluentdBufferHigh
            expr: fluentd_output_status_buffer_total_bytes > 200000000
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Fluentd buffer usage high"
              description: "Fluentd buffer is over 200MB ({{ $value }} bytes). Logs may be accumulating."
          
          - alert: FluentdOutputFailed
            expr: rate(fluentd_output_status_num_errors[5m]) > 0
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: "Fluentd output errors detected"
              description: "Fluentd is experiencing output errors ({{ $value }} errors/sec)"
          
          # üîç ELASTICSEARCH ALERTS
          - alert: ElasticsearchClusterRed
            expr: elasticsearch_cluster_health_status{color="red"} == 1
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "üö® Elasticsearch cluster is RED"
              description: "Elasticsearch cluster health is RED - data loss may occur!"
          
          - alert: ElasticsearchClusterYellow
            expr: elasticsearch_cluster_health_status{color="yellow"} == 1
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Elasticsearch cluster is YELLOW"
              description: "Elasticsearch cluster health is YELLOW - some replicas are missing"
          
          - alert: ElasticsearchHeapUsageHigh
            expr: (elasticsearch_jvm_memory_used_bytes{area="heap"} / elasticsearch_jvm_memory_max_bytes{area="heap"}) * 100 > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Elasticsearch heap usage high"
              description: "Elasticsearch heap usage is {{ $value }}% (should be <85%)"
          
          - alert: ElasticsearchDiskSpaceHigh
            expr: (1 - (elasticsearch_filesystem_data_available_bytes / elasticsearch_filesystem_data_size_bytes)) * 100 > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Elasticsearch disk space high"
              description: "Elasticsearch disk usage is {{ $value }}% (should be <85%)"
  
  # RECORDING RULES - Pre-calculate expensive queries
  recording_rules.yml: |
    groups:
      - name: microservice_recording_rules
        interval: 30s
        rules:
          # Pre-calculate CPU usage per pod
          - record: pod:cpu_usage:rate5m
            expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (pod, namespace)
          
          # Pre-calculate memory usage per pod
          - record: pod:memory_usage:bytes
            expr: sum(container_memory_usage_bytes) by (pod, namespace)
          
          # Pre-calculate request rate per service
          - record: service:http_requests:rate5m
            expr: sum(rate(http_requests_total[5m])) by (service)
          
          # Pre-calculate error rate per service
          - record: service:http_errors:rate5m
            expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          
          # Pre-calculate PostgreSQL query rate
          - record: postgres:query_rate:rate5m
            expr: sum(rate(pg_stat_database_tup_fetched[5m])) by (datname)
          
          # Pre-calculate Redis hit ratio
          - record: redis:hit_ratio:percent
            expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) * 100
          
          # Pre-calculate RabbitMQ message rate
          - record: rabbitmq:message_rate:rate5m
            expr: sum(rate(rabbitmq_queue_messages_published_total[5m])) by (queue)
